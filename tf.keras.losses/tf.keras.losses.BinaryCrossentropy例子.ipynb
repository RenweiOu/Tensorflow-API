{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a063a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# 设置numpy浮点数的长度\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e396e79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices(\"GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e08625",
   "metadata": {},
   "source": [
    "### 二元交叉熵损失\n",
    "\n",
    "+ y_pred是样本属于类别1的分数\n",
    "+ from_logits=True表示分数需要经过sigmoid函数概率化\n",
    "+ reduction参数设置为None，表示返回所有样本的损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0d60166",
   "metadata": {},
   "outputs": [],
   "source": [
    "bce_auto = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "bce_none = tf.keras.losses.BinaryCrossentropy(from_logits=True,\n",
    "                reduction=tf.keras.losses.Reduction.NONE)\n",
    "\n",
    "bce_sum = tf.keras.losses.BinaryCrossentropy(from_logits=True,\n",
    "                reduction=tf.keras.losses.Reduction.SUM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7084cd7f",
   "metadata": {},
   "source": [
    "+ 假设现在有4个样本，类别分别是0, 0, 1, 1\n",
    "+ BinaryCrossentropy()是以batch为计算单位，如果是一维数组，相当于只有一个batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecbc4e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这样的二维数据相当于4个batch\n",
    "y_true_1 = [[0], [1], [0], [0]]\n",
    "y_pred_1 = [[-18.6], [0.51], [2.94], [-12.8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "753ff5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这样的一维数据其实就是相当于一个batch\n",
    "y_true_2 = [0, 1, 0, 0]\n",
    "y_pred_2 = [-18.6, 0.51, 2.94, -12.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba0e5944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2个batch\n",
    "y_true_3 = [[0, 1], [0, 0]]\n",
    "y_pred_3 = [[-18.6, 0.51], [2.94, -12.8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb0d6b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.865458"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 各个样本的损失值，通过API的计算结果如下\n",
    "bce_auto(y_true_1, y_pred_1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75afda57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.   , 0.47 , 2.992, 0.   ], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bce_none(y_true_1, y_pred_1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8181f9a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.461832"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bce_sum(y_true_1, y_pred_1).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1853ed",
   "metadata": {},
   "source": [
    "对第二批数据进行计算，三种reduction结果都一样，因为第二批数据只有一个batch，而bce函数实际上只会计算每个batch的损失值(注意这里每个batch的损失值是指这个batch中所有样本损失值的平均值)，然后再根据reduction参数，是返回每个batch的损失值还是求和，或者计算全体batch的平均值(reduction=auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2831aada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.865458"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bce_auto(y_true_2, y_pred_2).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16aa3819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.865458"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bce_none(y_true_2, y_pred_2).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d52395ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.865458"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bce_sum(y_true_2, y_pred_2).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ae3113",
   "metadata": {},
   "source": [
    "第三批数据的计算结果，关于reduction参数只需要记住一点，就是bce函数是在batch这个维度上对损失值进行处理的，而不是对每个样本进行单独的计算，而在batch这个维度上，batch的损失值是该batch中所有样本损失的平均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c10f63c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.865458"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 所有batch损失值的平均值\n",
    "bce_auto(y_true_3, y_pred_3).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f63e18b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.235, 1.496], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 每个batch的损失值\n",
    "bce_none(y_true_3, y_pred_3).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4690c0ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.730916"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 所有batch损失值的和\n",
    "bce_sum(y_true_3, y_pred_3).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6eb5aa",
   "metadata": {},
   "source": [
    "### 现在手动模拟一遍，使用sigmoid函数将预测值概率化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8a555c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_2 = [0, 1, 0, 0]\n",
    "y_pred_2 = [-18.6, 0.51, 2.94, -12.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7caf05f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.   , 0.625, 0.95 , 0.   ], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# t是样本属于1类别的概率\n",
    "t = tf.keras.activations.sigmoid(tf.constant(y_pred_2))\n",
    "t.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c01b3831",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_2 = [0, 1, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569b064c",
   "metadata": {},
   "source": [
    "得到概率值后，下面计算交叉熵损失，交叉熵损失的公式是：$-p(x)logq(x)$, 二分类问题中p(x)=1, 而q(x)是样本正确类别的概率，例如样本x_1是1类别，那么q(x_1)就是其属于1类别的概率，而与其属于0类别的概率无关，即只关注样本对应的正确类别的概率(这一点在softmax的多分类交叉熵中是一样的)\n",
    "\n",
    "由于二分类问题没有使用独热编码，因此损失函数一般写成$: -[p(x)logq(x) + (1-p(x))log(1-q(x))]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9d92a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([-0.   ,  0.47 ,  2.992,  0.   ], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def crossEntropy(y_true, y_pred):\n",
    "    return -(y_true * tf.math.log(y_pred) + (1 - y_true) * tf.math.log(1 - y_pred))\n",
    "\n",
    "# 根据样本的正确类别计算每个样本的交叉熵损失，可以看到与API计算的结果一致\n",
    "crossEntropy(np.array(y_true_2), t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
